{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:28.057122Z",
     "iopub.status.busy": "2024-12-11T14:09:28.056505Z",
     "iopub.status.idle": "2024-12-11T14:09:28.063394Z",
     "shell.execute_reply": "2024-12-11T14:09:28.062743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: METAFLOW_PROFILE=dev-valay\n",
      "env: METAFLOW_UI_URL=\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide\n",
    "%env METAFLOW_PROFILE=dev-valay\n",
    "%env METAFLOW_UI_URL=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:28.094560Z",
     "iopub.status.busy": "2024-12-11T14:09:28.094125Z",
     "iopub.status.idle": "2024-12-11T14:09:28.097003Z",
     "shell.execute_reply": "2024-12-11T14:09:28.096536Z"
    }
   },
   "outputs": [],
   "source": [
    "#meta:tag=hide\n",
    "import os\n",
    "os.makedirs(\"temp_files\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `@model` Usage Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- START doctoc -->\n",
    "<!-- END doctoc -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Features\n",
    "- Model Saving: Save models with unique identifiers and metadata\n",
    "- Object Loading: Load objects saved with `current.model.save()`/ `current.checkpoint.save()`/ `current.huggingface_hub.snapshot_download()`\n",
    "- Version Control: Track different versions of models to derive lineage\n",
    "- Metadata Management: Attach metadata about saved/loaded models    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "`@model` decorator injects a `model` object in `current.` Users can call `current.model.save()` to save models. This returns a dictionary (`ModelArtifact`) containing metadata about the saved model. This dictionary contains several key pieces of information that help track and identify the saved model.\n",
    "\n",
    "The reference contains the following keys:\n",
    "```python\n",
    "{\n",
    "    \"key\": str,          # Unique storage key/path for the model\n",
    "    \"uuid\": str,         # Unique identifier for the model\n",
    "    \"type\": str,         # Type of artifact (always \"model\")\n",
    "    \"pathspec\": str,     # Metaflow pathspec (flow/run/step/task)\n",
    "    \"attempt\": int,      # Attempt number of the task\n",
    "    \"created_on\": str,   # ISO format timestamp of when model was saved\n",
    "    \"size\": int,         # Size of the saved model in bytes\n",
    "    \"url\": str,          # Full URL/path to the stored model\n",
    "    \"metadata\": dict,    # User-provided metadata (optional)\n",
    "    \"label\": str        # User-provided label (optional)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:28.099169Z",
     "iopub.status.busy": "2024-12-11T14:09:28.098853Z",
     "iopub.status.idle": "2024-12-11T14:09:28.102948Z",
     "shell.execute_reply": "2024-12-11T14:09:28.102493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_save_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_save_basic.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current\n",
    "import os  #meta_hide_line\n",
    "import json  #meta_hide_line\n",
    "\n",
    "class ModelSavingFlow(FlowSpec):\n",
    "    \n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        import uuid\n",
    "        # ... Create some model files ...\n",
    "        with open(\"model.h5\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v1 \"+ uuid.uuid4().hex) #meta_hide_line\n",
    "            \n",
    "        self.basic_model = current.model.save(\n",
    "            \"model.h5\",\n",
    "            label=\"basic_model\",\n",
    "            metadata={\n",
    "                \"version\": \"1.0\",\n",
    "                \"accuracy\": 0.95\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # ... save model into some directory ...\n",
    "        os.makedirs(\"model_directory\", exist_ok=True) #meta_hide_line\n",
    "        with open(\"model_directory/weights.txt\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v2\") #meta_hide_line\n",
    "        with open(\"model_directory/config.json\", \"w\") as f: #meta_hide_line\n",
    "            json.dump({\"layers\": 3}, f) #meta_hide_line\n",
    "            \n",
    "        self.directory_model = current.model.save(\n",
    "            \"./model_directory\",\n",
    "            label=\"keras_model\",\n",
    "            metadata={\n",
    "                \"loss\": \"2.0\",                \n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Store just the key for later use\n",
    "        self.model_key = self.directory_model[\"key\"]\n",
    "        print(f\"Model key: {self.model_key}\")\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step  #meta_hide_line\n",
    "    def end(self):  #meta_hide_line\n",
    "        pass  #meta_hide_line\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelSavingFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:28.105063Z",
     "iopub.status.busy": "2024-12-11T14:09:28.104739Z",
     "iopub.status.idle": "2024-12-11T14:09:47.412092Z",
     "shell.execute_reply": "2024-12-11T14:09:47.411351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelSavingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:32.243 \u001b[0m\u001b[1mWorkflow starting (run-id 7454):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:33.227 \u001b[0m\u001b[32m[7454/start/47442 (pid 2203585)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:36.692 \u001b[0m\u001b[32m[7454/start/47442 (pid 2203585)] \u001b[0m\u001b[22mModel key: mf.models/models/artifacts/keras_model_5680bf7d3344450697a1f340900f4878\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:44.112 \u001b[0m\u001b[32m[7454/start/47442 (pid 2203585)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:44.421 \u001b[0m\u001b[32m[7454/end/47443 (pid 2204272)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:46.411 \u001b[0m\u001b[32m[7454/end/47443 (pid 2204272)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:46.531 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=start\n",
    "! python temp_files/model_save_basic.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "The `@model` decorator can be used to load models from previous steps. The `load` argument can be given the name of the Metaflow DataArtifact that contains the return value of `current.model.save()`/ `current.checkpoint.save()` / `current.huggingface_hub.snapshot_download()`. The path to the loaded models will be accessible via `current.model.loaded`.\n",
    "\n",
    "`current.model.loaded` is a dictionary-like object that manages loaded models. It provides access to loaded model paths and their associated metadata. The The `current.model.loaded.info` property provides access to model metadata of the loaded models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:47.415505Z",
     "iopub.status.busy": "2024-12-11T14:09:47.414852Z",
     "iopub.status.idle": "2024-12-11T14:09:47.420803Z",
     "shell.execute_reply": "2024-12-11T14:09:47.420195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_basic.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current\n",
    "import os  #meta_hide_line\n",
    "import json  #meta_hide_line\n",
    "\n",
    "class ModelSavingFlow(FlowSpec):\n",
    "    \n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        import uuid #meta_hide_line\n",
    "        # ... Create some model files ...\n",
    "        with open(\"model.h5\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v1 \"+ uuid.uuid4().hex) #meta_hide_line\n",
    "            \n",
    "        self.basic_model = current.model.save(\n",
    "            \"model.h5\",\n",
    "            label=\"basic_model\",\n",
    "            metadata={\n",
    "                \"accuracy\": 0.95\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @model(load=[\"basic_model\"]) # Reference the model set to self\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_directory = current.model.loaded[\"basic_model\"]\n",
    "            # Access the path to the file like this:\n",
    "        model_path = os.path.join(\n",
    "            model_directory,\n",
    "            \"model.h5\"\n",
    "        )\n",
    "        print(\"Model Path %s Exists: %s\" % (model_path, os.path.exists(model_path)))\n",
    "        print(\"Loaded model from pathspec: %s\" % current.model.loaded.info[\"basic_model\"][\"pathspec\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelSavingFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:09:47.423456Z",
     "iopub.status.busy": "2024-12-11T14:09:47.422989Z",
     "iopub.status.idle": "2024-12-11T14:10:06.697555Z",
     "shell.execute_reply": "2024-12-11T14:10:06.696938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelSavingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:51.723 \u001b[0m\u001b[1mWorkflow starting (run-id 7455):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:09:52.709 \u001b[0m\u001b[32m[7455/start/47445 (pid 2204584)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:00.096 \u001b[0m\u001b[32m[7455/start/47445 (pid 2204584)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:00.397 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:01.687 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `basic_model` [type:model] with key: mf.models/models/artifacts/basic_model_a60f0fbea2264e558114de5a169bc73f\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:01.739 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[22m[@model] Loaded artifact `basic_model[type:model]` in 0.05 seconds\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:10:01.764 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[22mModel Path /tmp/metaflow_models_basic_model_sr3vtg2v/model.h5 Exists: True\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:05.609 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[22mLoaded model from pathspec: ModelSavingFlow/7455/start/47445\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:05.773 \u001b[0m\u001b[32m[7455/end/47447 (pid 2204922)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:05.886 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_basic.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading HuggingFace Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:10:06.700352Z",
     "iopub.status.busy": "2024-12-11T14:10:06.699850Z",
     "iopub.status.idle": "2024-12-11T14:10:06.703766Z",
     "shell.execute_reply": "2024-12-11T14:10:06.703335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_hf_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_hf_basic.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current, huggingface_hub\n",
    "import os\n",
    "\n",
    "class HFModelFlow(FlowSpec):\n",
    "    \n",
    "    @huggingface_hub\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.hf_model = current.huggingface_hub.snapshot_download(\n",
    "            repo_id=\"bert-base-uncased\"\n",
    "        )\n",
    "        self.next(self.end)\n",
    "\n",
    "    @model(load=[\"hf_model\"]) # Reference the model set to self\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_path = current.model.loaded[\"hf_model\"]\n",
    "        print(\"Directory contents of hf_model: %s\" % os.listdir(model_path))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    HFModelFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:10:06.706171Z",
     "iopub.status.busy": "2024-12-11T14:10:06.705844Z",
     "iopub.status.idle": "2024-12-11T14:10:49.971866Z",
     "shell.execute_reply": "2024-12-11T14:10:49.971245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mHFModelFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:11.844 \u001b[0m\u001b[1mWorkflow starting (run-id 7456):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:13.182 \u001b[0m\u001b[32m[7456/start/47450 (pid 2205302)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:16.233 \u001b[0m\u001b[32m[7456/start/47450 (pid 2205302)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:16.515 \u001b[0m\u001b[32m[7456/end/47451 (pid 2205399)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:17.707 \u001b[0m\u001b[32m[7456/end/47451 (pid 2205399)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `hf_model` [type:checkpoint] with key: mf.huggingface_hub/checkpoints/artifacts/HFModelFlow/start/26ec4b03ee0e/a92ae9615600/1a471abc.0.9b5c6e8800.0\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:44.722 \u001b[0m\u001b[32m[7456/end/47451 (pid 2205399)] \u001b[0m\u001b[22m[@model] Loaded artifact `hf_model[type:checkpoint]` in 27.01 seconds\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:10:44.746 \u001b[0m\u001b[32m[7456/end/47451 (pid 2205399)] \u001b[0m\u001b[22mDirectory contents of hf_model: ['README.md', 'config.json', '.gitattributes', 'LICENSE', 'flax_model.msgpack', 'tf_model.h5', 'tokenizer.json', 'pytorch_model.bin', 'vocab.txt', 'model.onnx', 'rust_model.ot', 'model.safetensors', 'tokenizer_config.json']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:49.185 \u001b[0m\u001b[32m[7456/end/47451 (pid 2205399)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:49.325 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_hf_basic.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:10:49.974633Z",
     "iopub.status.busy": "2024-12-11T14:10:49.974230Z",
     "iopub.status.idle": "2024-12-11T14:10:49.978681Z",
     "shell.execute_reply": "2024-12-11T14:10:49.978231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_chckpt_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_chckpt_basic.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current, checkpoint\n",
    "import os\n",
    "import json\n",
    "\n",
    "class CheckpointFlow(FlowSpec):\n",
    "    \n",
    "    @checkpoint\n",
    "    @step\n",
    "    def start(self):\n",
    "        # ... Created some checkpoint in checkpoint_dir...\n",
    "        os.makedirs(\"checkpoint_dir\", exist_ok=True) #meta_hide_line\n",
    "        with open(\"checkpoint_dir/weights.txt\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v2\") #meta_hide_line\n",
    "        with open(\"checkpoint_dir/config.json\", \"w\") as f: #meta_hide_line\n",
    "            json.dump({\"layers\": 3}, f) #meta_hide_line\n",
    "            \n",
    "        self.checkpoint_foo = current.checkpoint.save(\n",
    "            \"./checkpoint_dir\",\n",
    "            metadata={\n",
    "                \"version\": \"2.0\",\n",
    "            }\n",
    "        )\n",
    "        self.next(self.end)\n",
    "\n",
    "    @model(load=[\"checkpoint_foo\"]) # Reference the model set to self\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_path = current.model.loaded[\"checkpoint_foo\"]\n",
    "        print(\"Directory contents of hf_model: %s\" % os.listdir(model_path))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    CheckpointFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:10:49.980806Z",
     "iopub.status.busy": "2024-12-11T14:10:49.980401Z",
     "iopub.status.idle": "2024-12-11T14:11:14.106902Z",
     "shell.execute_reply": "2024-12-11T14:11:14.106055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mCheckpointFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:54.181 \u001b[0m\u001b[1mWorkflow starting (run-id 7457):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:10:55.192 \u001b[0m\u001b[32m[7457/start/47456 (pid 2206111)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:06.264 \u001b[0m\u001b[32m[7457/start/47456 (pid 2206111)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:06.633 \u001b[0m\u001b[32m[7457/end/47458 (pid 2206295)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:08.021 \u001b[0m\u001b[32m[7457/end/47458 (pid 2206295)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `checkpoint_foo` [type:checkpoint] with key: mf.checkpoints/checkpoints/artifacts/CheckpointFlow/start/26ec4b03ee0e/a92ae9615600/54d4b3b1.0.mfchckpt.0\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:08.985 \u001b[0m\u001b[32m[7457/end/47458 (pid 2206295)] \u001b[0m\u001b[22m[@model] Loaded artifact `checkpoint_foo[type:checkpoint]` in 0.96 seconds\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:09.014 \u001b[0m\u001b[32m[7457/end/47458 (pid 2206295)] \u001b[0m\u001b[22mDirectory contents of hf_model: ['config.json', 'weights.txt']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:13.160 \u001b[0m\u001b[32m[7457/end/47458 (pid 2206295)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:13.380 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_chckpt_basic.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading to specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:14.110206Z",
     "iopub.status.busy": "2024-12-11T14:11:14.109932Z",
     "iopub.status.idle": "2024-12-11T14:11:14.115484Z",
     "shell.execute_reply": "2024-12-11T14:11:14.114871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_basic_specific_path.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_basic_specific_path.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current\n",
    "import os  #meta_hide_line\n",
    "import json  #meta_hide_line\n",
    "\n",
    "class ModelSavingFlow(FlowSpec):\n",
    "    \n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        import uuid\n",
    "        # ... Create some model files ...\n",
    "        os.makedirs(\"model_directory\", exist_ok=True) #meta_hide_line\n",
    "        with open(\"model_directory/weights.txt\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v2\") #meta_hide_line\n",
    "        with open(\"model_directory/config.json\", \"w\") as f: #meta_hide_line\n",
    "            json.dump({\"layers\": 3}, f) #meta_hide_line\n",
    "            \n",
    "        self.basic_model = current.model.save(\n",
    "            \"./model_directory\",\n",
    "            label=\"basic_model\",\n",
    "            metadata={\n",
    "                \"version\": \"1.0\",\n",
    "                \"accuracy\": 0.95\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @model(load=[(\"basic_model\", \"./models/basic_model\")]) # Reference the model set to self\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_directory = current.model.loaded[\"basic_model\"]\n",
    "        print(\"Model Path %s contains contents: %s\" % (model_directory, os.listdir(model_directory)))\n",
    "        print(\"Loaded model from pathspec: %s\" % current.model.loaded.info[\"basic_model\"][\"pathspec\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelSavingFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:14.118085Z",
     "iopub.status.busy": "2024-12-11T14:11:14.117863Z",
     "iopub.status.idle": "2024-12-11T14:11:33.482156Z",
     "shell.execute_reply": "2024-12-11T14:11:33.481537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelSavingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:18.299 \u001b[0m\u001b[1mWorkflow starting (run-id 7458):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:19.257 \u001b[0m\u001b[32m[7458/start/47460 (pid 2206429)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:27.028 \u001b[0m\u001b[32m[7458/start/47460 (pid 2206429)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:27.362 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:28.434 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `basic_model` [type:model] with key: mf.models/models/artifacts/basic_model_5d1f468cd35142a685de10b117644da4\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:28.499 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[22m[@model] Loaded artifact `basic_model[type:model]` in 0.06 seconds\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:11:28.523 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[22mModel Path ./models/basic_model contains contents: ['config.json', 'weights.txt']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:32.374 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[22mLoaded model from pathspec: ModelSavingFlow/7458/start/47460\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:32.564 \u001b[0m\u001b[32m[7458/end/47461 (pid 2206552)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:32.683 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_basic_specific_path.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models from Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:33.484931Z",
     "iopub.status.busy": "2024-12-11T14:11:33.484437Z",
     "iopub.status.idle": "2024-12-11T14:11:33.488928Z",
     "shell.execute_reply": "2024-12-11T14:11:33.488466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_basic_key.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_basic_key.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current\n",
    "import os  #meta_hide_line\n",
    "import json  #meta_hide_line\n",
    "\n",
    "class ModelSavingFlow(FlowSpec):\n",
    "    \n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        import uuid\n",
    "        # ... Create some model files ...\n",
    "        os.makedirs(\"model_directory\", exist_ok=True) #meta_hide_line\n",
    "        with open(\"model_directory/weights.txt\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v2\") #meta_hide_line\n",
    "        with open(\"model_directory/config.json\", \"w\") as f: #meta_hide_line\n",
    "            json.dump({\"layers\": 3}, f) #meta_hide_line\n",
    "            \n",
    "        self.basic_model = current.model.save(\n",
    "            \"./model_directory\",\n",
    "            label=\"basic_model\",\n",
    "            metadata={\n",
    "                \"version\": \"1.0\",\n",
    "                \"accuracy\": 0.95\n",
    "            }\n",
    "        )\n",
    "        self.model_key = self.basic_model[\"key\"]\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @model(load=[\"model_key\"]) # Reference the model set to self\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_directory = current.model.loaded[\"model_key\"]\n",
    "        print(\"Model Path %s contains contents:: %s\" % (model_directory, os.listdir(model_directory)))\n",
    "        print(\"Loaded model from pathspec: %s\" % current.model.loaded.info[\"model_key\"][\"pathspec\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelSavingFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:33.490890Z",
     "iopub.status.busy": "2024-12-11T14:11:33.490590Z",
     "iopub.status.idle": "2024-12-11T14:11:51.831680Z",
     "shell.execute_reply": "2024-12-11T14:11:51.831031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelSavingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:37.596 \u001b[0m\u001b[1mWorkflow starting (run-id 7459):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:38.406 \u001b[0m\u001b[32m[7459/start/47463 (pid 2206677)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:45.649 \u001b[0m\u001b[32m[7459/start/47463 (pid 2206677)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:45.936 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:47.085 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `model_key` [type:model] with key: mf.models/models/artifacts/basic_model_e1417661935b42e88efc7c14d06a0305\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:47.134 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[22m[@model] Loaded artifact `model_key[type:model]` in 0.05 seconds\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:11:47.154 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[22mModel Path /tmp/metaflow_models_model_key_nhb3wmsb contains contents:: ['config.json', 'weights.txt']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:50.737 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[22mLoaded model from pathspec: ModelSavingFlow/7459/start/47463\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:50.936 \u001b[0m\u001b[32m[7459/end/47464 (pid 2206798)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:51.078 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_basic_key.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:51.834616Z",
     "iopub.status.busy": "2024-12-11T14:11:51.834105Z",
     "iopub.status.idle": "2024-12-11T14:11:51.838316Z",
     "shell.execute_reply": "2024-12-11T14:11:51.837864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_basic_explicit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_basic_explicit.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, current\n",
    "import os  #meta_hide_line\n",
    "import json  #meta_hide_line\n",
    "\n",
    "class ModelSavingFlow(FlowSpec):\n",
    "    \n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        import uuid\n",
    "        # ... Create some model files ...\n",
    "        os.makedirs(\"model_directory\", exist_ok=True) #meta_hide_line\n",
    "        with open(\"model_directory/weights.txt\", \"w\") as f: #meta_hide_line\n",
    "            f.write(\"model weights v2\") #meta_hide_line\n",
    "        with open(\"model_directory/config.json\", \"w\") as f: #meta_hide_line\n",
    "            json.dump({\"layers\": 3}, f) #meta_hide_line\n",
    "            \n",
    "        self.basic_model = current.model.save(\n",
    "            \"./model_directory\",\n",
    "            label=\"basic_model\",\n",
    "            metadata={\n",
    "                \"version\": \"1.0\",\n",
    "                \"accuracy\": 0.95\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @model\n",
    "    @step  \n",
    "    def end(self): \n",
    "        model_directory = current.model.load(self.basic_model)\n",
    "        print(\"Model Path %s contains contents: %s\" % (model_directory, os.listdir(model_directory)))\n",
    "        print(\"Loaded model from pathspec: %s\" % self.basic_model[\"pathspec\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelSavingFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:11:51.840207Z",
     "iopub.status.busy": "2024-12-11T14:11:51.839872Z",
     "iopub.status.idle": "2024-12-11T14:12:11.561117Z",
     "shell.execute_reply": "2024-12-11T14:12:11.560543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelSavingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:55.874 \u001b[0m\u001b[1mWorkflow starting (run-id 7460):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:11:56.717 \u001b[0m\u001b[32m[7460/start/47467 (pid 2206931)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:04.380 \u001b[0m\u001b[32m[7460/start/47467 (pid 2206931)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:04.643 \u001b[0m\u001b[32m[7460/end/47468 (pid 2207078)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:06.095 \u001b[0m\u001b[32m[7460/end/47468 (pid 2207078)] \u001b[0m\u001b[22m[@model] Loaded artifact `4ad1a6[type:model]` in 0.05 seconds\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:10.520 \u001b[0m\u001b[32m[7460/end/47468 (pid 2207078)] \u001b[0m\u001b[22mModel Path /tmp/metaflow_models_4ad1a6_8tpih9kw contains contents: ['config.json', 'weights.txt']\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:12:10.520 \u001b[0m\u001b[32m[7460/end/47468 (pid 2207078)] \u001b[0m\u001b[22mLoaded model from pathspec: ModelSavingFlow/7460/start/47467\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:10.684 \u001b[0m\u001b[32m[7460/end/47468 (pid 2207078)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:10.802 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=end\n",
    "! python temp_files/model_load_basic_explicit.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models Across Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading from Event Triggered Flows\n",
    "\n",
    "```python\n",
    "from metaflow import FlowSpec, step, trigger_on_finish, current, model\n",
    "@trigger_on_finish(flow='ModelRefreshFlow')\n",
    "class InferenceFlow(FlowSpec):\n",
    "\n",
    "    @model\n",
    "    @step\n",
    "    def start(self):\n",
    "        print(\"Triggering run\", current.trigger.run)\n",
    "        model_path = current.model.load(current.trigger.run.data.model_reference)\n",
    "        # The ModelRefreshFlow contained a `self.model_artifact` set to the return value of \n",
    "        # `current.model.save()`/ `current.checkpoint.save()` / `current.huggingface_hub.snapshot_download()`. \n",
    "        print(\"Model path\", model_path)\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Models with Metaflow Client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:12:11.563812Z",
     "iopub.status.busy": "2024-12-11T14:12:11.563335Z",
     "iopub.status.idle": "2024-12-11T14:12:11.567621Z",
     "shell.execute_reply": "2024-12-11T14:12:11.567193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_client_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_client_api.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import Flow, current, namespace, model, FlowSpec, step\n",
    "from metaflow.client import Step, Task\n",
    "import os\n",
    "import time  #meta_hide_line\n",
    "\n",
    "class InferenceFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        # Get model key from previous flow\n",
    "        run = Flow('ModelSavingFlow').latest_successful_run\n",
    "        self.upstream_model = run.data.basic_model\n",
    "        self.next(self.load_model)\n",
    "    \n",
    "    @model(load=[\"upstream_model\"])\n",
    "    @step\n",
    "    def load_model(self):\n",
    "        # Decorator-based loading\n",
    "        model_path = current.model.loaded[\"upstream_model\"]\n",
    "        print(f\"Loaded via decorator to: {model_path} with contents: {os.listdir(model_path)}\")\n",
    "        \n",
    "        time.sleep(5) #meta_hide_line\n",
    "        # Manual loading\n",
    "        manual_path = current.model.load(\n",
    "            self.upstream_model,\n",
    "            path=\"./manual_load\"\n",
    "        )\n",
    "        print(f\"Loaded manually to: {manual_path} with contents: {os.listdir(manual_path)}\")\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    InferenceFlow()  #meta_hide_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:12:11.569559Z",
     "iopub.status.busy": "2024-12-11T14:12:11.569248Z",
     "iopub.status.idle": "2024-12-11T14:12:33.556255Z",
     "shell.execute_reply": "2024-12-11T14:12:33.555630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mInferenceFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:15.437 \u001b[0m\u001b[1mWorkflow starting (run-id 7461):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:16.402 \u001b[0m\u001b[32m[7461/start/47470 (pid 2207204)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:19.133 \u001b[0m\u001b[32m[7461/start/47470 (pid 2207204)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:19.390 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:20.557 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `upstream_model` [type:model] with key: mf.models/models/artifacts/basic_model_6483655edd5e44dfb2675968dd23b229\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:20.598 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[22m[@model] Loaded artifact `upstream_model[type:model]` in 0.04 seconds\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:20.620 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[22mLoaded via decorator to: /tmp/metaflow_models_upstream_model_bgb_77uz with contents: ['config.json', 'weights.txt']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:25.662 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[22m[@model] Loaded artifact `4ad1a6[type:model]` in 0.04 seconds\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:12:25.662 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[22mLoaded manually to: ./manual_load with contents: ['config.json', 'weights.txt']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:30.405 \u001b[0m\u001b[32m[7461/load_model/47471 (pid 2207244)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:30.841 \u001b[0m\u001b[32m[7461/end/47473 (pid 2207356)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:32.725 \u001b[0m\u001b[32m[7461/end/47473 (pid 2207356)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:32.834 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:tag=hide_input\n",
    "#meta:show_steps=load_model\n",
    "! python temp_files/model_load_client_api.py run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Using Parameters\n",
    "\n",
    "Every model artifact saved with `current.model.save()` is assigned a unique key. This key is present in the `ModelArtifact` dictionary returned by `current.model.save()`. This can also be used to load models across flows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:12:33.559037Z",
     "iopub.status.busy": "2024-12-11T14:12:33.558559Z",
     "iopub.status.idle": "2024-12-11T14:12:33.562497Z",
     "shell.execute_reply": "2024-12-11T14:12:33.562082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp_files/model_load_key_param.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_files/model_load_key_param.py\n",
    "#meta:tag=hide_output\n",
    "from metaflow import FlowSpec, step, model, Parameter, current\n",
    "\n",
    "class ModelConsumerFlow(FlowSpec):\n",
    "    # Model key is the key of the model artifact saved with current.model.save()\n",
    "    # This key can be accessed via the `key` property of dictionary returned by \n",
    "    # `current.model.save()` / `current.checkpoint.save()` / `current.huggingface_hub.snapshot_download()`\n",
    "    model_key = Parameter('model-key', \n",
    "                         help=\"Key of the model to load\")\n",
    "\n",
    "    @model(load=[(\"model_key\", \"./models/consumer\")])\n",
    "    @step\n",
    "    def start(self):\n",
    "        # Model is loaded to ./model directory\n",
    "        import os\n",
    "        print(\"Model files:\", os.listdir(\"./models/consumer\"))\n",
    "        print(\"Loaded model from pathspec: %s\" % current.model.loaded.info[\"model_key\"][\"pathspec\"])\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":  #meta_hide_line\n",
    "    ModelConsumerFlow()  #meta_hide_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:12:33.564419Z",
     "iopub.status.busy": "2024-12-11T14:12:33.564117Z",
     "iopub.status.idle": "2024-12-11T14:12:46.792223Z",
     "shell.execute_reply": "2024-12-11T14:12:46.791613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.12.36.post9-git09d02cb-dirty+obcheckpoint(0.1.4);ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mModelConsumerFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:valay@outerbounds.co\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:37.563 \u001b[0m\u001b[1mWorkflow starting (run-id 7462):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:38.472 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:39.706 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[22m[@model] Loading Artifact with name `model_key` [type:model] with key: mf.models/models/artifacts/basic_model_828f6108847e44cf8e79d95781434788\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:39.801 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[22m[@model] Loaded artifact `model_key[type:model]` in 0.09 seconds\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:39.823 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[22mModel files: ['config.json', 'weights.txt']\u001b[0m\r\n",
      "\u001b[35m2024-12-11 06:12:39.823 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[22mLoaded model from pathspec: ModelSavingFlow/7083/start/45856\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:43.714 \u001b[0m\u001b[32m[7462/start/47475 (pid 2207435)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:44.074 \u001b[0m\u001b[32m[7462/end/47477 (pid 2207517)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:45.945 \u001b[0m\u001b[32m[7462/end/47477 (pid 2207517)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2024-12-11 06:12:46.060 \u001b[0m\u001b[1mDone!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#meta:show_steps=start\n",
    "! python temp_files/model_load_key_param.py run --model-key mf.models/models/artifacts/basic_model_828f6108847e44cf8e79d95781434788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models After Flow Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:12:46.794846Z",
     "iopub.status.busy": "2024-12-11T14:12:46.794449Z",
     "iopub.status.idle": "2024-12-11T14:12:47.682659Z",
     "shell.execute_reply": "2024-12-11T14:12:47.682183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created for pathspec ModelSavingFlow/7460/start/47467\n",
      "Model files: ['config.json', 'weights.txt']\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow \n",
    "from metaflow import load_model\n",
    "run = Flow('ModelSavingFlow').latest_successful_run\n",
    "upstream_model = run.data.basic_model\n",
    "load_model(upstream_model, path=\"./models/notebook-load\")\n",
    "print(\n",
    "    \"Model created for pathspec\", run.data.basic_model[\"pathspec\"]\n",
    ")\n",
    "print(\"Model files:\", os.listdir(\"./models/notebook-load\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf-modeling-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
